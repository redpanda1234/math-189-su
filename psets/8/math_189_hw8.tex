\documentclass[189]{pset}

% ================================================================== %
%                                                                    %
%                              Document                              %
%                                                                    %
% ================================================================== %

% ----------------------- Header formatting ------------------------ %

\name{Forest Kobayashi}
\class{Math of Big Data}
\season{Summer}
\prof{Gu}
\assignment{8}
\duedate{05/24/2018}
\dueday{Thursday}
\problems{1, 2}
\acknowledgements{{}, {}}
\onTime{0}

\comments{\textbf{Comments:} Feel free to work with other students,
  but make sure you write up the homework and code on your own (no
  copying homework \textit{or} code; no pair programming). Feel free
  to ask students or instructors for help debugging code or whatever
  else, though.

  The starter files for problem 1 and extra credit can be found under
  the Resource tab on course website. Please print out all the graphs
  generated by your own code and submit them together with the written
  part, and make sure you upload the code to your Github repository.}

\lfoot{Due Thursday, May 24th 2018}

\usepackage{hyperref}

\begin{document}

% --------------------------- Problem 1 ---------------------------- %

  \section{(K-means)}
    In this problem, we will implement the k-means algorithm and
    separate 5,000 2D data points into different number of clusters.

    Let $X = {x_1, x_2 \ldots, x_m} $ be the data points, and let $k$
    be the number of clusters. The k-means algorithm is summarized as
    following:
    \begin{enumerate}[label=\arabic*.]
      \item Randomly initialize $k$ cluster centers, $\mu_1, \mu_2
        \ldots \mu_k$, in the feature space.
      \item Calculate the distance between each data points and the
        cluster centers.
      \item Assign each data point to the cluster center $c$ whose
        distance between this data point is the minimum of all the
        cluster centers, namely,
        \[
          c_i = \argmin_j \norm{x_i - \mu_j}^2
        \]
      \item Update each cluster center to be
        \[
          \mu_j = \frac{\sum_{i=1}^{m}1\{c_i = j\}x_i}{\sum_{i =
              1}^{m}1\{c_i = j\}}
        \]
      \item Repeat step 2 - 4 until convergence or exhausted.
    \end{enumerate}

    The objective (cost) function is defined as
    \[
      J(c, \mu) = \sum_{i = 1}^{m} \norm{x_i - \mu_{c_i}}^2
    \]

    In this assignment, you will first implement the k-means cost
    function and the algorithm. Then, for $k = 1, 2 \ldots, 20$, find
    the number of clusters with the optimal cost and produce a plot of
    the relationship between the cost and the number of clusters.
    Then, visualize the data points and the cluster centers on the
    optimal number of clusters.

    Notice that the k-means algorithm might yield different results
    based on the randomness of the initialization of cluster centers.

  \hrulefill

  \section*{Solution:}
  \begin{figure}[H]
    \centering
    \includegraphics{kmeans_1.png}
    \caption{K-means}
    \label{fig:k-means}
  \end{figure}
  \begin{figure}[H]
    \centering
    \includegraphics{kmeans_2.png}
    \caption{K-means}
    \label{fig:k-means}
  \end{figure}

  \clearpage

% --------------------------- Problem 2 ---------------------------- %

  \section{Extra Credit (Non-Negative Matrix Factorization)}
    In this problem, we will use the reuters dataset in nltk library.
    Please run nltk.download() in python shell to download the
    dataset. In the starter code, we have already parsed the data for
    you.

    Choosing an appropriate objective function and algorithm from Lee
    and Seung
    2001\footnote{\url{https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf}}
    implement Non-Negative Matrix Factorization for topic modelling
    (choose an appropriate number of topics/latent features) and
    assert that the convergence properties proved in the paper hold.
    Display the 20 most relevant words for each of the topics you
    discover.

  \hrulefill

  \section*{Solution:}


% --------------------------- Problem 3 ---------------------------- %

  \section{Extra Credit (Linear Regression)}
    Consider the Bayesian Linear Regression model with the following
    generative process:
    \begin{enumerate}[label=\arabic*.]
      \item Draw $\vw \sim \cN(\0, \mb{V}_0)$
      \item Draw $\vy_i \sim \cN(\vw^\T\vx_i, \sigma^2)$ for
        $i=1,2,\dots,n$ where $\sigma^2$ is known.
    \end{enumerate}
    Express this model as a directed graphical model using Plate
    notation. Is $\vy_i$ independent of $\vw$? Is $\vy_i$ independent
    of $\vw$ \textit{given} $\cD = \{\vx_i\}$? Support these claims.

  \hrulefill

  \section*{Solution:}


\end{document}
